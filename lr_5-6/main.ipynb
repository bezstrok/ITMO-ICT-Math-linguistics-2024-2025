{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Задание 5.4",
   "id": "c3fc52bb9bad9690"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:54:16.272038Z",
     "start_time": "2025-03-09T09:54:16.268786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import typing as tp\n",
    "from dataclasses import dataclass, field"
   ],
   "id": "c1abaf9def3a4a96",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:54:16.764017Z",
     "start_time": "2025-03-09T09:54:16.761044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass(frozen=True)\n",
    "class TokenSpecifier:\n",
    "    name: tp.Optional[str]\n",
    "    pattern: str\n",
    "    regex: re.Pattern = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        object.__setattr__(self, 'regex', re.compile(self.pattern))\n",
    "\n",
    "    def __bool__(self) -> bool:\n",
    "        return self.name is not None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"TokenSpecifier(name={self.name!r}, pattern={self.pattern!r})\""
   ],
   "id": "b9bf01a65f9b08aa",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:54:17.293137Z",
     "start_time": "2025-03-09T09:54:17.290255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass(frozen=True)\n",
    "class TokenInstance:\n",
    "    value: str\n",
    "    token: TokenSpecifier\n",
    "    position_start: int\n",
    "    position_end: int\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return (f\"TokenInstance(token={self.token.name}, \"\n",
    "                f\"value={self.value!r}, \"\n",
    "                f\"start={self.position_start}, end={self.position_end})\")"
   ],
   "id": "b5ed6b366f05bc1d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-09T09:54:17.766298Z",
     "start_time": "2025-03-09T09:54:17.764488Z"
    }
   },
   "source": [
    "RESERVED_WORDS: set[str] = {\n",
    "    \"package\",\n",
    "    \"import\",\n",
    "    \"func\",\n",
    "    \"var\",\n",
    "    \"if\",\n",
    "    \"else\",\n",
    "    \"for\",\n",
    "    \"return\",\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:54:18.495897Z",
     "start_time": "2025-03-09T09:54:18.492260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TOKENS: list[TokenSpecifier] = [\n",
    "    TokenSpecifier(None, r\"\\s+\"),\n",
    "    TokenSpecifier(None, r\"//.*\"),\n",
    "    TokenSpecifier(None, r\"/\\*[\\s\\S]*?\\*/\"),\n",
    "    TokenSpecifier('STRING', r'\"(?:\\\\.|[^\"\\\\])*\"'),\n",
    "    TokenSpecifier('NUMBER', r\"-?\\d+(\\.\\d+)?([eE][-+]?\\d+)?\"),\n",
    "    TokenSpecifier('RESERVED', r'\\b(?:' + '|'.join(RESERVED_WORDS) + r')\\b'),\n",
    "    TokenSpecifier('IDENTIFIER', r'\\b[A-Za-z_][A-Za-z0-9_]*\\b'),\n",
    "    TokenSpecifier('OPERATOR', r'\\+|\\-|\\*|\\/|%|==|=|!=|<=|>=|<|>|&&|\\|\\||!'),\n",
    "    TokenSpecifier('SEPARATOR', r'\\(|\\)|\\{|\\}|\\[|\\]|;|,|\\.|:'),\n",
    "]"
   ],
   "id": "909e65f43759bd27",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:54:22.346335Z",
     "start_time": "2025-03-09T09:54:22.341127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(code: str) -> list[TokenInstance]:\n",
    "    pos = 0\n",
    "    tokens: list[TokenInstance] = []\n",
    "\n",
    "    while pos < len(code):\n",
    "        match_found: tp.Optional[re.Match[str]] = None\n",
    "        for spec in TOKENS:\n",
    "            match_found = spec.regex.match(code, pos)\n",
    "            if match_found:\n",
    "                value = match_found.group(0)\n",
    "                if spec:\n",
    "                    token_instance = TokenInstance(\n",
    "                        value=value,\n",
    "                        token=spec,\n",
    "                        position_start=pos,\n",
    "                        position_end=match_found.end()\n",
    "                    )\n",
    "                    tokens.append(token_instance)\n",
    "                pos = match_found.end()\n",
    "                break\n",
    "        if not match_found:\n",
    "            raise SyntaxError(f\"Лексическая ошибка в позиции {pos}: {code[pos:pos + 20]!r}\")\n",
    "\n",
    "    return tokens"
   ],
   "id": "b915cf15d1fb5361",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:54:23.457947Z",
     "start_time": "2025-03-09T09:54:23.454685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze(code: str) -> None:\n",
    "    try:\n",
    "        tokens = tokenize(code)\n",
    "        print(\"Лексемы:\")\n",
    "        for token in tokens:\n",
    "            print(token)\n",
    "        print(\"Лексический анализ завершён успешно. Ошибок нет.\")\n",
    "    except SyntaxError as e:\n",
    "        print(\"Лексическая ошибка:\", e)"
   ],
   "id": "d6e8242b0e57caff",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:54:24.214440Z",
     "start_time": "2025-03-09T09:54:24.211022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_code_1 = \"\"\"package main\n",
    "import \"fmt\"\n",
    "func main() {\n",
    "    var x = 42\n",
    "    if x > 0 {\n",
    "        fmt.Println(\"Positive\")\n",
    "    } else {\n",
    "        fmt.Println(\"Non-positive\")\n",
    "    }\n",
    "}\"\"\""
   ],
   "id": "9f4108104a7f0403",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:54:24.477491Z",
     "start_time": "2025-03-09T09:54:24.474912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_code_2 = \"\"\"package main\n",
    "func main() {\n",
    "    var x = 3$14\n",
    "}\"\"\""
   ],
   "id": "777bc1953a36c8da",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:54:24.756895Z",
     "start_time": "2025-03-09T09:54:24.754265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_code_3 = \"\"\"package calc\n",
    "func add(a int, b int) int {\n",
    "    return a + b\n",
    "}\n",
    "func main() {\n",
    "    var result = add(3.14, -2.71e-1)\n",
    "    fmt.Println(result)\n",
    "}\"\"\""
   ],
   "id": "67180a9c0ed8bbdb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:54:25.241255Z",
     "start_time": "2025-03-09T09:54:25.239486Z"
    }
   },
   "cell_type": "code",
   "source": "tests: list[str] = [test_code_1, test_code_2, test_code_3]",
   "id": "10a7a38e3d31c791",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T09:54:25.903899Z",
     "start_time": "2025-03-09T09:54:25.900481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, code in enumerate(tests, 1):\n",
    "    print(f\"\\n----- Тест {i} -----\")\n",
    "    analyze(code)"
   ],
   "id": "8da095ca77e7a914",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Тест 1 -----\n",
      "Лексемы:\n",
      "TokenInstance(token=RESERVED, value='package', start=0, end=7)\n",
      "TokenInstance(token=IDENTIFIER, value='main', start=8, end=12)\n",
      "TokenInstance(token=RESERVED, value='import', start=13, end=19)\n",
      "TokenInstance(token=STRING, value='\"fmt\"', start=20, end=25)\n",
      "TokenInstance(token=RESERVED, value='func', start=26, end=30)\n",
      "TokenInstance(token=IDENTIFIER, value='main', start=31, end=35)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=35, end=36)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=36, end=37)\n",
      "TokenInstance(token=SEPARATOR, value='{', start=38, end=39)\n",
      "TokenInstance(token=RESERVED, value='var', start=44, end=47)\n",
      "TokenInstance(token=IDENTIFIER, value='x', start=48, end=49)\n",
      "TokenInstance(token=OPERATOR, value='=', start=50, end=51)\n",
      "TokenInstance(token=NUMBER, value='42', start=52, end=54)\n",
      "TokenInstance(token=RESERVED, value='if', start=59, end=61)\n",
      "TokenInstance(token=IDENTIFIER, value='x', start=62, end=63)\n",
      "TokenInstance(token=OPERATOR, value='>', start=64, end=65)\n",
      "TokenInstance(token=NUMBER, value='0', start=66, end=67)\n",
      "TokenInstance(token=SEPARATOR, value='{', start=68, end=69)\n",
      "TokenInstance(token=IDENTIFIER, value='fmt', start=78, end=81)\n",
      "TokenInstance(token=SEPARATOR, value='.', start=81, end=82)\n",
      "TokenInstance(token=IDENTIFIER, value='Println', start=82, end=89)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=89, end=90)\n",
      "TokenInstance(token=STRING, value='\"Positive\"', start=90, end=100)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=100, end=101)\n",
      "TokenInstance(token=SEPARATOR, value='}', start=106, end=107)\n",
      "TokenInstance(token=RESERVED, value='else', start=108, end=112)\n",
      "TokenInstance(token=SEPARATOR, value='{', start=113, end=114)\n",
      "TokenInstance(token=IDENTIFIER, value='fmt', start=123, end=126)\n",
      "TokenInstance(token=SEPARATOR, value='.', start=126, end=127)\n",
      "TokenInstance(token=IDENTIFIER, value='Println', start=127, end=134)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=134, end=135)\n",
      "TokenInstance(token=STRING, value='\"Non-positive\"', start=135, end=149)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=149, end=150)\n",
      "TokenInstance(token=SEPARATOR, value='}', start=155, end=156)\n",
      "TokenInstance(token=SEPARATOR, value='}', start=157, end=158)\n",
      "Лексический анализ завершён успешно. Ошибок нет.\n",
      "\n",
      "----- Тест 2 -----\n",
      "Лексическая ошибка: Лексическая ошибка в позиции 40: '$14\\n}'\n",
      "\n",
      "----- Тест 3 -----\n",
      "Лексемы:\n",
      "TokenInstance(token=RESERVED, value='package', start=0, end=7)\n",
      "TokenInstance(token=IDENTIFIER, value='calc', start=8, end=12)\n",
      "TokenInstance(token=RESERVED, value='func', start=13, end=17)\n",
      "TokenInstance(token=IDENTIFIER, value='add', start=18, end=21)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=21, end=22)\n",
      "TokenInstance(token=IDENTIFIER, value='a', start=22, end=23)\n",
      "TokenInstance(token=IDENTIFIER, value='int', start=24, end=27)\n",
      "TokenInstance(token=SEPARATOR, value=',', start=27, end=28)\n",
      "TokenInstance(token=IDENTIFIER, value='b', start=29, end=30)\n",
      "TokenInstance(token=IDENTIFIER, value='int', start=31, end=34)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=34, end=35)\n",
      "TokenInstance(token=IDENTIFIER, value='int', start=36, end=39)\n",
      "TokenInstance(token=SEPARATOR, value='{', start=40, end=41)\n",
      "TokenInstance(token=RESERVED, value='return', start=46, end=52)\n",
      "TokenInstance(token=IDENTIFIER, value='a', start=53, end=54)\n",
      "TokenInstance(token=OPERATOR, value='+', start=55, end=56)\n",
      "TokenInstance(token=IDENTIFIER, value='b', start=57, end=58)\n",
      "TokenInstance(token=SEPARATOR, value='}', start=59, end=60)\n",
      "TokenInstance(token=RESERVED, value='func', start=61, end=65)\n",
      "TokenInstance(token=IDENTIFIER, value='main', start=66, end=70)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=70, end=71)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=71, end=72)\n",
      "TokenInstance(token=SEPARATOR, value='{', start=73, end=74)\n",
      "TokenInstance(token=RESERVED, value='var', start=79, end=82)\n",
      "TokenInstance(token=IDENTIFIER, value='result', start=83, end=89)\n",
      "TokenInstance(token=OPERATOR, value='=', start=90, end=91)\n",
      "TokenInstance(token=IDENTIFIER, value='add', start=92, end=95)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=95, end=96)\n",
      "TokenInstance(token=NUMBER, value='3.14', start=96, end=100)\n",
      "TokenInstance(token=SEPARATOR, value=',', start=100, end=101)\n",
      "TokenInstance(token=NUMBER, value='-2.71e-1', start=102, end=110)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=110, end=111)\n",
      "TokenInstance(token=IDENTIFIER, value='fmt', start=116, end=119)\n",
      "TokenInstance(token=SEPARATOR, value='.', start=119, end=120)\n",
      "TokenInstance(token=IDENTIFIER, value='Println', start=120, end=127)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=127, end=128)\n",
      "TokenInstance(token=IDENTIFIER, value='result', start=128, end=134)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=134, end=135)\n",
      "TokenInstance(token=SEPARATOR, value='}', start=136, end=137)\n",
      "Лексический анализ завершён успешно. Ошибок нет.\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
