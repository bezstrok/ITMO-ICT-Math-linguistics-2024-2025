{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Задание 5.4",
   "id": "c3fc52bb9bad9690"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.220996Z",
     "start_time": "2025-03-09T11:19:47.217717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import typing as tp\n",
    "from dataclasses import dataclass, field"
   ],
   "id": "c1abaf9def3a4a96",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.227198Z",
     "start_time": "2025-03-09T11:19:47.224023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass(frozen=True)\n",
    "class TokenSpecifier:\n",
    "    name: tp.Optional[str]\n",
    "    pattern: str\n",
    "    regex: re.Pattern = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        object.__setattr__(self, 'regex', re.compile(self.pattern))\n",
    "\n",
    "    def __bool__(self) -> bool:\n",
    "        return self.name is not None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"TokenSpecifier(name={self.name!r}, pattern={self.pattern!r})\""
   ],
   "id": "b9bf01a65f9b08aa",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.300623Z",
     "start_time": "2025-03-09T11:19:47.298457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass(frozen=True)\n",
    "class TokenInstance:\n",
    "    value: str\n",
    "    token: TokenSpecifier\n",
    "    position_start: int\n",
    "    position_end: int\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return (f\"TokenInstance(token={self.token.name}, \"\n",
    "                f\"value={self.value!r}, \"\n",
    "                f\"start={self.position_start}, end={self.position_end})\")"
   ],
   "id": "b5ed6b366f05bc1d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.305281Z",
     "start_time": "2025-03-09T11:19:47.303897Z"
    }
   },
   "source": [
    "RESERVED_WORDS: set[str] = {\n",
    "    \"package\",\n",
    "    \"import\",\n",
    "    \"func\",\n",
    "    \"var\",\n",
    "    \"if\",\n",
    "    \"else\",\n",
    "    \"for\",\n",
    "    \"return\",\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.312185Z",
     "start_time": "2025-03-09T11:19:47.309874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TOKENS: list[TokenSpecifier] = [\n",
    "    TokenSpecifier(None, r\"\\s+\"),\n",
    "    TokenSpecifier(None, r\"//.*\"),\n",
    "    TokenSpecifier(None, r\"/\\*[\\s\\S]*?\\*/\"),\n",
    "    TokenSpecifier('STRING', r'\"(?:\\\\.|[^\"\\\\])*\"'),\n",
    "    TokenSpecifier('NUMBER', r\"-?\\d+(\\.\\d+)?([eE][-+]?\\d+)?\"),\n",
    "    TokenSpecifier('RESERVED', r'\\b(?:' + '|'.join(RESERVED_WORDS) + r')\\b'),\n",
    "    TokenSpecifier('IDENTIFIER', r'\\b[A-Za-z_][A-Za-z0-9_]*\\b'),\n",
    "    TokenSpecifier('OPERATOR', r'\\+|\\-|\\*|\\/|%|==|=|!=|<=|>=|<|>|&&|\\|\\||!'),\n",
    "    TokenSpecifier('SEPARATOR', r'\\(|\\)|\\{|\\}|\\[|\\]|;|,|\\.|:'),\n",
    "]"
   ],
   "id": "909e65f43759bd27",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.318411Z",
     "start_time": "2025-03-09T11:19:47.316200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(code: str) -> list[TokenInstance]:\n",
    "    pos = 0\n",
    "    tokens: list[TokenInstance] = []\n",
    "\n",
    "    while pos < len(code):\n",
    "        match_found: tp.Optional[re.Match[str]] = None\n",
    "        for spec in TOKENS:\n",
    "            match_found = spec.regex.match(code, pos)\n",
    "            if match_found:\n",
    "                value = match_found.group(0)\n",
    "                if spec:\n",
    "                    token_instance = TokenInstance(\n",
    "                        value=value,\n",
    "                        token=spec,\n",
    "                        position_start=pos,\n",
    "                        position_end=match_found.end()\n",
    "                    )\n",
    "                    tokens.append(token_instance)\n",
    "                pos = match_found.end()\n",
    "                break\n",
    "        if not match_found:\n",
    "            raise SyntaxError(f\"Лексическая ошибка в позиции {pos}: {code[pos:pos + 20]!r}\")\n",
    "\n",
    "    return tokens"
   ],
   "id": "b915cf15d1fb5361",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.323506Z",
     "start_time": "2025-03-09T11:19:47.321925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze(code: str) -> None:\n",
    "    try:\n",
    "        tokens = tokenize(code)\n",
    "        print(\"Лексемы:\")\n",
    "        for token in tokens:\n",
    "            print(token)\n",
    "        print(\"Лексический анализ завершён успешно. Ошибок нет.\")\n",
    "    except SyntaxError as e:\n",
    "        print(\"Лексическая ошибка:\", e)"
   ],
   "id": "d6e8242b0e57caff",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.328432Z",
     "start_time": "2025-03-09T11:19:47.327082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_code_1 = \"\"\"package main\n",
    "import \"fmt\"\n",
    "func main() {\n",
    "    var x = 42\n",
    "    if x > 0 {\n",
    "        fmt.Println(\"Positive\")\n",
    "    } else {\n",
    "        fmt.Println(\"Non-positive\")\n",
    "    }\n",
    "}\"\"\""
   ],
   "id": "9f4108104a7f0403",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.332860Z",
     "start_time": "2025-03-09T11:19:47.331625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_code_2 = \"\"\"package main\n",
    "func main() {\n",
    "    var x = 3$14\n",
    "}\"\"\""
   ],
   "id": "777bc1953a36c8da",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.337353Z",
     "start_time": "2025-03-09T11:19:47.336061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_code_3 = \"\"\"package calc\n",
    "func add(a int, b int) int {\n",
    "    return a + b\n",
    "}\n",
    "func main() {\n",
    "    var result = add(3.14, -2.71e-1)\n",
    "    fmt.Println(result)\n",
    "}\"\"\""
   ],
   "id": "67180a9c0ed8bbdb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.342041Z",
     "start_time": "2025-03-09T11:19:47.340715Z"
    }
   },
   "cell_type": "code",
   "source": "tests: list[str] = [test_code_1, test_code_2, test_code_3]",
   "id": "10a7a38e3d31c791",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.348625Z",
     "start_time": "2025-03-09T11:19:47.346770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, code in enumerate(tests, 1):\n",
    "    print(f\"\\n----- Тест {i} -----\")\n",
    "    analyze(code)"
   ],
   "id": "8da095ca77e7a914",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Тест 1 -----\n",
      "Лексемы:\n",
      "TokenInstance(token=RESERVED, value='package', start=0, end=7)\n",
      "TokenInstance(token=IDENTIFIER, value='main', start=8, end=12)\n",
      "TokenInstance(token=RESERVED, value='import', start=13, end=19)\n",
      "TokenInstance(token=STRING, value='\"fmt\"', start=20, end=25)\n",
      "TokenInstance(token=RESERVED, value='func', start=26, end=30)\n",
      "TokenInstance(token=IDENTIFIER, value='main', start=31, end=35)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=35, end=36)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=36, end=37)\n",
      "TokenInstance(token=SEPARATOR, value='{', start=38, end=39)\n",
      "TokenInstance(token=RESERVED, value='var', start=44, end=47)\n",
      "TokenInstance(token=IDENTIFIER, value='x', start=48, end=49)\n",
      "TokenInstance(token=OPERATOR, value='=', start=50, end=51)\n",
      "TokenInstance(token=NUMBER, value='42', start=52, end=54)\n",
      "TokenInstance(token=RESERVED, value='if', start=59, end=61)\n",
      "TokenInstance(token=IDENTIFIER, value='x', start=62, end=63)\n",
      "TokenInstance(token=OPERATOR, value='>', start=64, end=65)\n",
      "TokenInstance(token=NUMBER, value='0', start=66, end=67)\n",
      "TokenInstance(token=SEPARATOR, value='{', start=68, end=69)\n",
      "TokenInstance(token=IDENTIFIER, value='fmt', start=78, end=81)\n",
      "TokenInstance(token=SEPARATOR, value='.', start=81, end=82)\n",
      "TokenInstance(token=IDENTIFIER, value='Println', start=82, end=89)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=89, end=90)\n",
      "TokenInstance(token=STRING, value='\"Positive\"', start=90, end=100)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=100, end=101)\n",
      "TokenInstance(token=SEPARATOR, value='}', start=106, end=107)\n",
      "TokenInstance(token=RESERVED, value='else', start=108, end=112)\n",
      "TokenInstance(token=SEPARATOR, value='{', start=113, end=114)\n",
      "TokenInstance(token=IDENTIFIER, value='fmt', start=123, end=126)\n",
      "TokenInstance(token=SEPARATOR, value='.', start=126, end=127)\n",
      "TokenInstance(token=IDENTIFIER, value='Println', start=127, end=134)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=134, end=135)\n",
      "TokenInstance(token=STRING, value='\"Non-positive\"', start=135, end=149)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=149, end=150)\n",
      "TokenInstance(token=SEPARATOR, value='}', start=155, end=156)\n",
      "TokenInstance(token=SEPARATOR, value='}', start=157, end=158)\n",
      "Лексический анализ завершён успешно. Ошибок нет.\n",
      "\n",
      "----- Тест 2 -----\n",
      "Лексическая ошибка: Лексическая ошибка в позиции 40: '$14\\n}'\n",
      "\n",
      "----- Тест 3 -----\n",
      "Лексемы:\n",
      "TokenInstance(token=RESERVED, value='package', start=0, end=7)\n",
      "TokenInstance(token=IDENTIFIER, value='calc', start=8, end=12)\n",
      "TokenInstance(token=RESERVED, value='func', start=13, end=17)\n",
      "TokenInstance(token=IDENTIFIER, value='add', start=18, end=21)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=21, end=22)\n",
      "TokenInstance(token=IDENTIFIER, value='a', start=22, end=23)\n",
      "TokenInstance(token=IDENTIFIER, value='int', start=24, end=27)\n",
      "TokenInstance(token=SEPARATOR, value=',', start=27, end=28)\n",
      "TokenInstance(token=IDENTIFIER, value='b', start=29, end=30)\n",
      "TokenInstance(token=IDENTIFIER, value='int', start=31, end=34)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=34, end=35)\n",
      "TokenInstance(token=IDENTIFIER, value='int', start=36, end=39)\n",
      "TokenInstance(token=SEPARATOR, value='{', start=40, end=41)\n",
      "TokenInstance(token=RESERVED, value='return', start=46, end=52)\n",
      "TokenInstance(token=IDENTIFIER, value='a', start=53, end=54)\n",
      "TokenInstance(token=OPERATOR, value='+', start=55, end=56)\n",
      "TokenInstance(token=IDENTIFIER, value='b', start=57, end=58)\n",
      "TokenInstance(token=SEPARATOR, value='}', start=59, end=60)\n",
      "TokenInstance(token=RESERVED, value='func', start=61, end=65)\n",
      "TokenInstance(token=IDENTIFIER, value='main', start=66, end=70)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=70, end=71)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=71, end=72)\n",
      "TokenInstance(token=SEPARATOR, value='{', start=73, end=74)\n",
      "TokenInstance(token=RESERVED, value='var', start=79, end=82)\n",
      "TokenInstance(token=IDENTIFIER, value='result', start=83, end=89)\n",
      "TokenInstance(token=OPERATOR, value='=', start=90, end=91)\n",
      "TokenInstance(token=IDENTIFIER, value='add', start=92, end=95)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=95, end=96)\n",
      "TokenInstance(token=NUMBER, value='3.14', start=96, end=100)\n",
      "TokenInstance(token=SEPARATOR, value=',', start=100, end=101)\n",
      "TokenInstance(token=NUMBER, value='-2.71e-1', start=102, end=110)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=110, end=111)\n",
      "TokenInstance(token=IDENTIFIER, value='fmt', start=116, end=119)\n",
      "TokenInstance(token=SEPARATOR, value='.', start=119, end=120)\n",
      "TokenInstance(token=IDENTIFIER, value='Println', start=120, end=127)\n",
      "TokenInstance(token=SEPARATOR, value='(', start=127, end=128)\n",
      "TokenInstance(token=IDENTIFIER, value='result', start=128, end=134)\n",
      "TokenInstance(token=SEPARATOR, value=')', start=134, end=135)\n",
      "TokenInstance(token=SEPARATOR, value='}', start=136, end=137)\n",
      "Лексический анализ завершён успешно. Ошибок нет.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Задание 6.1",
   "id": "e4887c661b52b4ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.363058Z",
     "start_time": "2025-03-09T11:19:47.355274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Parser:\n",
    "    _OPERATORS: set[str] = {\n",
    "        \"+\", \"-\", \"*\", \"/\", \"%\",\n",
    "        \"<\", \">\", \"<=\", \">=\", \"==\", \"!=\"\n",
    "    }\n",
    "\n",
    "    _STATEMENT_SEPARATOR: str = \";\"\n",
    "\n",
    "    def __init__(self, tokens: list[TokenInstance]):\n",
    "        self._tokens = tokens\n",
    "        self._pos = 0\n",
    "        self._valid_count = 0\n",
    "\n",
    "    @property\n",
    "    def valid_count(self) -> int:\n",
    "        return self._valid_count\n",
    "\n",
    "    def current_token(self) -> tp.Optional[TokenInstance]:\n",
    "        if self._pos < len(self._tokens):\n",
    "            return self._tokens[self._pos]\n",
    "        return None\n",
    "\n",
    "    def peek_token(self) -> tp.Optional[TokenInstance]:\n",
    "        if self._pos + 1 < len(self._tokens):\n",
    "            return self._tokens[self._pos + 1]\n",
    "        return None\n",
    "\n",
    "    def consume(\n",
    "        self,\n",
    "        expected_value: tp.Optional[str] = None,\n",
    "        expected_type: tp.Optional[str] = None\n",
    "    ) -> TokenInstance:\n",
    "        token = self.current_token()\n",
    "        if token is None:\n",
    "            raise SyntaxError(\"Неожиданный конец входа\")\n",
    "\n",
    "        if expected_value is not None and token.value != expected_value:\n",
    "            raise SyntaxError(\n",
    "                f\"Ожидалось {expected_value!r}, получено {token.value!r} \"\n",
    "                f\"на позиции {token.position_start}\"\n",
    "            )\n",
    "\n",
    "        if expected_type is not None and token.token.name != expected_type:\n",
    "            raise SyntaxError(\n",
    "                f\"Ожидался токен типа {expected_type!r}, \"\n",
    "                f\"получен {token.token.name!r} на позиции {token.position_start}\"\n",
    "            )\n",
    "\n",
    "        self._pos += 1\n",
    "        return token\n",
    "\n",
    "    def parse_program(self) -> None:\n",
    "        while self.current_token() is not None:\n",
    "            self.parse_statement()\n",
    "            self._valid_count += 1\n",
    "\n",
    "    def parse_statement(self) -> None:\n",
    "        token = self.current_token()\n",
    "        if token is None:\n",
    "            raise SyntaxError(\"Неожиданный конец входа в parse_statement\")\n",
    "\n",
    "        if token.token.name == \"RESERVED\" and token.value == \"if\":\n",
    "            self.parse_if()\n",
    "        elif token.token.name == \"RESERVED\" and token.value == \"for\":\n",
    "            self.parse_for()\n",
    "        elif token.token.name == \"IDENTIFIER\":\n",
    "            peek_token = self.peek_token()\n",
    "            if peek_token and peek_token.token.name == \"OPERATOR\" and peek_token.value == \"=\":\n",
    "                self.parse_assignment()\n",
    "            else:\n",
    "                self.parse_expression()\n",
    "        else:\n",
    "            self.parse_expression()\n",
    "\n",
    "    def parse_assignment(self, *, consume_separator: bool = True) -> None:\n",
    "        self.consume(expected_type=\"IDENTIFIER\")\n",
    "        op = self.consume(expected_type=\"OPERATOR\")\n",
    "        if op.value != \"=\":\n",
    "            raise SyntaxError(\n",
    "                f\"Ожидалось '=', получено {op.value} на позиции {op.position_start}\"\n",
    "            )\n",
    "\n",
    "        self.parse_expression()\n",
    "\n",
    "        if consume_separator:\n",
    "            maybe_sep = self.current_token()\n",
    "            if (maybe_sep and maybe_sep.token.name == \"SEPARATOR\"\n",
    "                and maybe_sep.value == self._STATEMENT_SEPARATOR):\n",
    "                self.consume(expected_value=self._STATEMENT_SEPARATOR)\n",
    "\n",
    "    def parse_if(self) -> None:\n",
    "        self.consume(expected_value=\"if\")\n",
    "        self.parse_expression()\n",
    "        self.parse_block()\n",
    "\n",
    "        token = self.current_token()\n",
    "        if token and token.token.name == \"RESERVED\" and token.value == \"else\":\n",
    "            self.consume(expected_value=\"else\")\n",
    "            self.parse_block()\n",
    "\n",
    "    def parse_for(self) -> None:\n",
    "        self.consume(expected_value=\"for\")\n",
    "        token = self.current_token()\n",
    "\n",
    "        if token and token.token.name == \"IDENTIFIER\":\n",
    "            peek_token = self.peek_token()\n",
    "            if peek_token and peek_token.token.name == \"OPERATOR\" and peek_token.value == \"=\":\n",
    "                self.parse_assignment(consume_separator=False)\n",
    "                self.consume(expected_value=self._STATEMENT_SEPARATOR)\n",
    "                self.parse_expression()\n",
    "                self.consume(expected_value=self._STATEMENT_SEPARATOR)\n",
    "                self.parse_assignment()\n",
    "            else:\n",
    "                self.parse_expression()\n",
    "        else:\n",
    "            self.parse_expression()\n",
    "\n",
    "        self.parse_block()\n",
    "\n",
    "    def parse_block(self) -> None:\n",
    "        self.consume(expected_value=\"{\")\n",
    "        while True:\n",
    "            token = self.current_token()\n",
    "            if token is None or token.value == \"}\":\n",
    "                break\n",
    "            self.parse_statement()\n",
    "        self.consume(expected_value=\"}\")\n",
    "\n",
    "    def parse_expression(self) -> None:\n",
    "        self.parse_term()\n",
    "        while True:\n",
    "            token = self.current_token()\n",
    "            if (token and token.token.name == \"OPERATOR\"\n",
    "                and token.value in self._OPERATORS):\n",
    "                self.consume()\n",
    "                self.parse_term()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    def parse_term(self) -> None:\n",
    "        token = self.current_token()\n",
    "        if token is None:\n",
    "            raise SyntaxError(\"Неожиданный конец выражения\")\n",
    "\n",
    "        if token.value == \"(\":\n",
    "            self.consume(expected_value=\"(\")\n",
    "            self.parse_expression()\n",
    "            self.consume(expected_value=\")\")\n",
    "        elif token.token.name in {\"NUMBER\", \"IDENTIFIER\", \"STRING\"}:\n",
    "            self.consume()\n",
    "        else:\n",
    "            raise SyntaxError(\n",
    "                f\"Неожиданный токен {token.value!r} на позиции {token.position_start}\"\n",
    "            )"
   ],
   "id": "2cc46c82a42613a2",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.370463Z",
     "start_time": "2025-03-09T11:19:47.368353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def syntactic_analyze(code: str) -> None:\n",
    "    try:\n",
    "        tokens = tokenize(code)\n",
    "        parser = Parser(tokens)\n",
    "        parser.parse_program()\n",
    "        print(f\"Синтаксический анализ завершён успешно.\")\n",
    "    except SyntaxError as e:\n",
    "        print(\"Синтаксическая ошибка:\", e)"
   ],
   "id": "f6676d9721514d40",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.376129Z",
     "start_time": "2025-03-09T11:19:47.374840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_code_1 = \"\"\"if x + 5 > 0 {\n",
    "    x = x + 1;\n",
    "    if x - 3 < 4 {\n",
    "        x = x + 2;\n",
    "    } else {\n",
    "        x = x - 2;\n",
    "    }\n",
    "} else {\n",
    "    y = 0;\n",
    "}\"\"\""
   ],
   "id": "dfc531832269c5b9",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.380874Z",
     "start_time": "2025-03-09T11:19:47.379532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_code_2 = \"\"\"for i = 10; i > 0; i = i - 1 {\n",
    "    sum = sum + i;\n",
    "}\n",
    "for x + 1 > 0 {\n",
    "    x = x + 2;\n",
    "}\"\"\""
   ],
   "id": "e562ece8269b49eb",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.385573Z",
     "start_time": "2025-03-09T11:19:47.384233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_code_3 = \"\"\"if a + 5 > 0 {\n",
    "    a = a + 2;\n",
    "else {\n",
    "    a = a + 3;\n",
    "}\"\"\""
   ],
   "id": "57928ad950e14b2d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.390301Z",
     "start_time": "2025-03-09T11:19:47.388996Z"
    }
   },
   "cell_type": "code",
   "source": "tests: list[str] = [test_code_1, test_code_2, test_code_3]",
   "id": "d39cb44bdb9463dc",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:19:47.397530Z",
     "start_time": "2025-03-09T11:19:47.395587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, code in enumerate(tests, 1):\n",
    "    print(f\"\\n----- Синтаксический тест {i} -----\")\n",
    "    syntactic_analyze(code)"
   ],
   "id": "752dd03ea6e746c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Синтаксический тест 1 -----\n",
      "Синтаксический анализ завершён успешно.\n",
      "\n",
      "----- Синтаксический тест 2 -----\n",
      "Синтаксический анализ завершён успешно.\n",
      "\n",
      "----- Синтаксический тест 3 -----\n",
      "Синтаксическая ошибка: Неожиданный токен 'else' на позиции 30\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
